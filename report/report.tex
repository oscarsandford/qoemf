% Based on the template for ICIP-2022 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx}

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}


\title{A Survey on the Importance of QoS Metrics Across Networking Domains}
\name{Juan Flores, Oscar Sandford, and Ben Wunderlich
\thanks{Thank you to Dr. Jianping Pan at the University of Victoria for his teaching and guidance throughout this project and the course.}}
\address{University of Victoria}
\begin{document}
%
\maketitle
%
\begin{abstract}
Write this last.
\end{abstract}
%
\begin{keywords}
Quality of service, survey
\end{keywords}
%
% Overview of the problem. Why is it important?
\section{Introduction}
The design of computer networks is compelled by a drive towards a target quality of experience (QoE) and quality of service (QoS). These measures define the success of 
a network service in a competitive market. It is important to make a distinction between QoE and QoS. QoS is the set of characteristics in a computer networks system that 
affect its ability to satisfy the utilitarian needs of its users \cite{qoe_qos_2014}. QoE focuses closer on the end-user, and includes user perception, expectation, and 
their specific experiences using the service \cite{qoe_qos_2010}. To expound on that, \cite{qoe_qos_2014} states that QoS is viewed from a system's perspective, and QoE 
from a user's perspective. This study will focus on quality of service, as it is easier to evaluate due to its quantitative nature. QoS requirements stem from domain and 
system requirements, rather than the requirements of an user-end, which are difficult to measure. In the interest of isolating the analysis of a network to its technical 
requirements and how well companies correctly prioritize the maintenance of their system in order to best fit a generalized view of the customers' needs, we will only 
consider quality of service (QoS) in this study.

Countless studies in computer networking have addressed quality of service when it comes to the development and analysis of new algorithms, measurements on the efficacy of 
existing solutions, as well as domain-specific requirements for specific systems. However, various domains are differing standards on quality of service for their 
applications. It is difficult to correctly understand what it means for an application to have a "good" quality of service, especially under the requirements of the 
application domain itself, without giving weights, or prioritization, to certain parameters. 

This paper surveys a set of well-defined, domain-agnostic quality of service parameters and defines each parameter's importance in the context of different networking 
domains. Such domains include online multiplayer gaming, peer-to-peer file transfer services, video streaming, and financial applications. 

% The design of computer networks is driven by a drive towards a target quality of service (QoS), a set of performance measurements. Further, the implementation of 
% network architectures demands time and money, and implementations that fail to meet quality of service standards waste time for both companies and customers. 
% Software-defined networks (SDN) addresses the project of static architectures by enabling programming and measurement in a dynamic setting. It is important to understand 
% and harness the strengths of SDN in a methodical way, so developers can focus more on the design goals and less on tedious implementation tasks. 

% There does not yet exist a qualitative evaluation of such measurement techniques for modern web servers such as Node.js. Providing a survey of various QoS measurement 
% metrics for this domain will enable web developers to better understand and optimize the QoS metrics that matter most to their application domain.

% What has already been done? Why are their efforts not sufficient?
\section{Related Work}
Software-defined networks (SDN) address the problem of static architectures by enabling programming and measurement in a dynamic setting. In order to help developers 
focus more on the design goals and less on tedious implementation tasks, SDN research has inspired the utilization of network emulators \cite{mininet_emulation_2014}. 
Network emulators are often used to test the quality of service of server architectures in a pseudo-live setting. Experiments with such emulators reveal key quality of 
service parameters that have been used in domain-agostic settings. 

Network emulation using Mininet in order to test quality of service parameters for TCP and UDP has been used in \cite{qos_analysis_2022, chauhan_atulkar_2020}. The 
metrics presented in \cite{qos_analysis_2022} include throughput, delay, packet loss, and jitter. The metrics are further defined as follows: 
\begin{itemize}
    \item Throughput (total transmitted data in bits)/(total time taken in seconds)
    \item Delay (time required to transmit the data from sender to receiver)
    \item Packet loss (the number of packets not delivered to their destination)
    \item Jitter (the variance in latency)
\end{itemize}
The authors used these metrics in a generic setting (i.e. no specific domain) in order to compare TCP and UDP protocols. While this domain-agnostic approach makes for 
a good start, there are several flaws in their results. Firstly, no packet loss was experienced, and that measurement was thereby ignored. Secondly, previous studies 
\cite{shamim2018performance, chauhan2020achieving, althobyani2018implementing} used round trip time (RTT) as a QoS metric, which \cite{qos_analysis_2022} did not consider. 

Another study that investigated load balancing algorithms looked at throughput, response time, and memory utilization \cite{babbar_2022}. Measuring memory utilization 
is effective for load balancing, but we are considering quality of service, with the focus on the end user. The weight on the server only matters if it affects the 
client. This paper reinforces throughput as a necessary metric, and that response time (or RTT) must be considered. 

A different paper \cite{AweQoS_2020} proposes a framework titled AweQoS which combines both quality of service tests with security and reliability tests. The framework 
includes bandwidth speed measurement, delay tests and jitter tests, as well as SYN flood test, UDP flood test, and Slow HTTP flood test. 

In order to provide foundation for quality of service analysis in differing domains, \cite{taxonomy} created a taxonomy for clustering specification into categories. 
We will reuse their specification in our approach, as well as extend it in relation to the domains we will be looking at. 


% What is our approach? Why can it do better or differently?
\section{Approach}
As we conclude our investigation on common quality of service metrics used in simulated and domain-agnostic settings, we compiled a set of general quality of service 
metrics as well as policies, according to specifications outlined in \cite{taxonomy}. The following hierarchy of parameters is based on \cite{taxonomy}, with additional 
notes pertaining to parameters discovered in related works discussed prior.

At this point, we make the distinction between metrics and parameters, where the former is a subset of the latter.

\begin{itemize}
    \item Metrics
    \begin{itemize}
        \item Security
        \item Performance
        \begin{itemize}
            \item Timeliness (e.g. delay)
            \item Precision (consistency, e.g. jitter)
            \item Accuracy (lack of errors, e.g. packet loss)
            \item Combinations (e.g. throughput)
        \end{itemize}
        \item Relative Importance (cost of given service to user)
    \end{itemize}
    \item Policies
    \begin{itemize}
        \item Management
        \item Levels of Service (lower QoS to maintain availability)
    \end{itemize}
\end{itemize}

Note the inclusion of security as a general metric. While many applications simply prioritize speed and reliability, security is key to some application domains. 
Reliability issues (system faults not as a result of a malicious attacker) are covered by the performance category. 


\subsection{Project Website}
Please see the associated website for progress reports and results at https://oscarsandford.github.io/qoemf/.

\section{Domains}

% RTS, FPS, MOBA, MMORPG, turn-based
\subsection{Online Multiplayer Games}

% Napster, Gnutella, BitTorrent
\subsection{P2P File Transfer}

% Twitch.tv, YouTube, Netflix, ..?
\subsection{Video Streaming}

% Discord, Skype, ..
\subsection{VoIP}


% Discussion, comparison, reflection on life...
\section{Discussion}
Text here.

% Wrap up and encourage further research in QoS.
\section{Conclusion}
Text here.

% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
\bibliographystyle{IEEEbib}
\bibliography{refs}

\end{document}
